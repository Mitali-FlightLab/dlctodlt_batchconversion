{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things you need to run the code:\n",
    "1. All your cam1 .h5 files in one folder. This will be the videos folder under the main DLC Project folder.\n",
    "2. Same as above for all your cam 2 .h5 files.\n",
    "\n",
    "Basically have all cam1 and all cam 2 h5 files in two different folders. \n",
    "\n",
    "3. Create a new folder where you want all your dltdv8 format points to be saved.\n",
    "\n",
    "To run the code:\n",
    "1. Import all the libraries and run the DLCh5_DLTcsv definition.\n",
    "\n",
    "2. set the following variables\n",
    "'all_cam1_paths' is the folder where all your cam1 .h5 files are.\n",
    "'all_cam2_paths' is the folder where all your cam2 .h5 files are.\n",
    "'output_path' is the folder where all your dlt coordinates will be dumped.\n",
    "\n",
    "3. RUNNN\n",
    "\n",
    "IMPORTANT: \n",
    "In creating the directory and saving the files part, you need to mention, which characters to pick from the cam1 path which will be different for every project. Change it accordingly. Use some online tool. try this https://www.lettercount.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLCh5_DLTcsv(Cam1_h5_path, Cam2_h5_path, output_path):\n",
    "    \"\"\"\n",
    "    Function to extract the labelled points into a csv file for DLTdv8\n",
    "    and to generate dummy offset, xyzpts and xyzres.csv files \n",
    "\n",
    "    Cam1_h5_path: A string of path to the h5 file of camera 1\n",
    "\n",
    "    Cam2_h5_path: A string of path to the h5 file of camera 2\n",
    "\n",
    "    \"\"\"\n",
    "    Cam1_h5 = pd.read_hdf(Cam1_h5_path) #Reading the h5 file from camera 1\n",
    "    Cam2_h5 = pd.read_hdf(Cam2_h5_path) #Reading the h5 file from camera 2\n",
    "    \n",
    "\n",
    "    #Making a dummy offsets file\n",
    "    offsets = pd.DataFrame(\n",
    "        columns=['cam1_offset','cam2_offset'],\n",
    "        index = np.array(Cam1_h5.index)\n",
    "        )\n",
    "    offsets['cam1_offset'] = np.zeros(shape = len(Cam1_h5))\n",
    "    offsets['cam2_offset'] = np.zeros(shape = len(Cam2_h5))\n",
    "    offsets = offsets.round(6) #Do I need this?\n",
    "\n",
    "    #Making a new Dataframe to save it as csv\n",
    "    xypts = pd.DataFrame(\n",
    "        columns=['pt1_cam1_X', 'pt1_cam1_Y', 'pt1_cam2_X', 'pt1_cam2_Y']\n",
    "        )\n",
    "    xypts[xypts.columns[0]] = np.array(Cam1_h5[Cam1_h5.columns[0]])\n",
    "    xypts[xypts.columns[1]] = np.array(Cam1_h5[Cam1_h5.columns[1]])\n",
    "    xypts[xypts.columns[2]] = np.array(Cam2_h5[Cam2_h5.columns[0]])\n",
    "    xypts[xypts.columns[3]] = np.array(Cam2_h5[Cam2_h5.columns[1]])\n",
    "    xypts = xypts.round(6)\n",
    "\n",
    "    #Making a new Dataframe with likelihoods of points\n",
    "    #Replicating likelihood columns for X and Y of each point\n",
    "    likelihood = pd.DataFrame(\n",
    "        columns = ['pt1_cam1_X', 'pt1_cam1_Y', 'pt1_cam2_X', 'pt1_cam2_Y']\n",
    "    )\n",
    "    likelihood[likelihood.columns[0]] = np.array(Cam1_h5[Cam1_h5.columns[2]])\n",
    "    likelihood[likelihood.columns[1]] = np.array(Cam1_h5[Cam1_h5.columns[2]])\n",
    "    likelihood[likelihood.columns[2]] = np.array(Cam2_h5[Cam2_h5.columns[2]])\n",
    "    likelihood[likelihood.columns[3]] = np.array(Cam2_h5[Cam2_h5.columns[2]])\n",
    "\n",
    "\n",
    "    #Filtering based on likelihood from DLC\n",
    "    pvalue = 0.95\n",
    "    cutoff = likelihood[likelihood.columns[:]] > pvalue\n",
    "    likelihood_filtered_xypts = xypts.mul(cutoff)\n",
    "    likelihood_filtered_xypts.replace(0, np.nan, inplace=True)\n",
    "\n",
    "    #Making a dummy xyzpts file\n",
    "    xyzpts = pd.DataFrame(\n",
    "        np.nan,\n",
    "        columns=['pt1_X', 'pt1_Y', 'pt1_Z',],\n",
    "        index = np.array(Cam1_h5.index)\n",
    "        )\n",
    "    \n",
    "    #Making a dummy xyzres file\n",
    "    xyzres = pd.DataFrame(\n",
    "        np.nan,\n",
    "        columns=['pt1_dltres'],\n",
    "        index = np.array(Cam1_h5.index)\n",
    "        )\n",
    "    \n",
    "\n",
    "    #Creating the directory and saving the csv files in the dir\n",
    "    cwd = os.getcwd()\n",
    "    file = Cam1_h5_path\n",
    "    file_dir = output_path\n",
    "    offsets.to_csv(file_dir+f'\\{file[77:86]}_offsets.csv',index = False)\n",
    "    xypts.to_csv(file_dir+f'\\{file[77:86]}_xypts.csv',index = False, na_rep='NaN')\n",
    "    likelihood.to_csv(file_dir+f'\\{file[77:86]}_likelihood.csv',index = False)\n",
    "    xyzpts.to_csv(file_dir+f'\\{file[77:86]}_xyzpts.csv',index = False, na_rep='NaN')\n",
    "    xyzres.to_csv(file_dir+f'\\{file[77:86]}_xyzres.csv',index = False, na_rep='NaN')\n",
    "\n",
    "    #Saving likelihood xypts and the supporting files\n",
    "    offsets.to_csv(file_dir+f'\\{file[77:86]}_likelihood_filtered_offsets.csv',index = False)\n",
    "    likelihood_filtered_xypts.to_csv(file_dir+f'\\{file[77:86]}_likelihood_filtered_xypts.csv',index = False, na_rep='NaN')\n",
    "    xyzpts.to_csv(file_dir+f'\\{file[77:86]}_likelihood_filtered_xyzpts.csv',index = False, na_rep='NaN')\n",
    "    xyzres.to_csv(file_dir+f'\\{file[77:86]}_likelihood_filtered_xyzres.csv',index = False, na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cam1_paths=glob.glob(r\"E:\\transparent chamber 3\\transapent chamber 3 20654-Mitali-2022-12-16\\videos\\*.h5\")\n",
    "all_cam2_paths=glob.glob(r\"E:\\transparent chamber 3\\transparent chamber 3 16024-Mitali-2022-12-16\\videos\\*.h5\")\n",
    "output_path = (r\"E:\\transparent chamber 3\\dlc2dlt\")\n",
    "\n",
    "allfiles = pd.DataFrame(list(zip(all_cam1_paths, all_cam2_paths)), columns = [\"cam1\",\"cam2\"])\n",
    "\n",
    "for vid_no in allfiles.index:\n",
    "    DLCh5_DLTcsv(allfiles['cam1'][vid_no], allfiles['cam2'][vid_no],output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83ee029d5d10d3f729f6823cca99f3200fa32d1d1a44fa89a3500044ea449067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
